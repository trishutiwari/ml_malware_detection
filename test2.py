from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.layers import Dense, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.models import Sequential
import matplotlib.pylab as plt
import numpy as np


# In order to correctly run this we are going to need a lot more data! 
batch_size = 100
num_classes = 4
# epochs = 30

# input image dimensions
# **********************************************************************
#*****************  INSTRUCTION ****************************************
# the variable img_x changes the number of rows in our matrix, the 
# greater the number the larger a single matrix but the fewer samples 
# we will have to train with. Ideally we should have like 5000 samples 
# with a matrix size of 50, 128 or 133. So we need more data ! 
#***********************************************************************
img_x, img_y = 20, 133

# Load the data into the model
# theData = np.load("cnnData.npy")
# theLabels = np.load("cnnLabels.npy")
# theData = np.reshape(theData, (len(theLabels), img_y))

# # Now format the data so the last element of each array is the label. 
# index = 0 
# tempData = np.array([]) 
# for data in theData: 
#   tempData = np.append(tempData, np.append(data, theLabels[index]))
#   index += 1

# tempData = np.reshape(tempData, (len(theData), img_y+1))

# print(len(tempData))

# # We are going to make matrixes with a height of 10 to do this we are going to ignore some packets...
# diff = len(tempData)%img_x 
# tempData = tempData[:len(tempData)-diff, :]
# print(len(tempData))

# # Now I need to make matrices with the same labels. 

# matrixData = np.array([np.zeros((img_x,img_y+1))])
# tempMatrix = np.array([np.zeros((img_x,img_y+1))]) 
# tempZeros = np.zeros(img_y)

# dataZero = tempData[0] 
# aLabel = dataZero[img_y]
# index = 0
# for data in tempData: 
#   # find the length of the current temporary matrix 
#   if index != img_x: 
#     # Check if the label matches the current labels we are looking at. 
#     if data[img_y] == aLabel: 
#       tempMatrix[0][index] = data
#       index += 1
#     else:
#       distFromTen = len(tempMatrix) % img_x
#       for i in range(0,distFromTen):
#         tempMatrix[0][index] = np.append(tempZeros, aLabel)
#         index += 1
#   elif index == img_x: 
#     matrixData = np.concatenate((matrixData, tempMatrix), axis=0)
#     tempMatrix = np.array([np.zeros((img_x,img_y+1))])
#     aLabel = data[img_y] 
#     index = 0
#     tempMatrix[0][index] = data
#     index += 1


# idxTrain = np.random.choice(len(matrixData), len(matrixData))
# matrixData = matrixData[idxTrain,] 

# # Now I want to grab the labels from the data before running the ConvNet
# randomLabels = matrixData[:, :, img_y:]
# matrixLabels = np.array([]) 

# for subMatrix in randomLabels:
#   matrixLabels = np.append(matrixLabels, subMatrix[0][0])

# #print(matrixLabels)

# # Now i want to convert the trainData to one-hot arrays
# oneHotLabels = keras.utils.to_categorical(matrixLabels, num_classes)


# # Make the test and training sets 
# justData = matrixData[:, :, 0:img_y]
# offset = int(len(justData) - len(justData)*0.2)
# trainData = justData[0:offset]
# trainData = trainData.reshape(trainData.shape[0], img_x, img_y, 1)
# trainLabels = oneHotLabels[0:offset]
# testData = justData[offset:]
# testData = testData.reshape(testData.shape[0], img_x, img_y, 1)
# testLabels = oneHotLabels[offset:]

input_shape = (img_x, img_y,1)

# np.save("cnnTrainData", trainData)
# np.save("cnnTestData", testData)
# np.save("cnnTrainLabels", trainLabels)
# np.save("cnnTestLabels", testLabels)

trainData = np.load("cnnTrainData.npy")
testData = np.load("cnnTestData.npy")
trainLabels = np.load("cnnTrainLabels.npy")
testLabels = np.load("cnnTestLabels.npy")
#******************************************************************************
#******************************************************************************
# ************************ The following is the Model *************************
#******************************************************************************

model = Sequential()

#******************************************************************************
#*************** This makes the convolution layer of the model ****************
# Model Parameters: 
# Kernel Size: The kernel size divides the size of the matrix... So if your 
# matrix dimensions are 10,128 and you have a kernel of 2 then the outcome will
# be 5,64. 
# Strides: how quickly the kernel filter moves around the original image. 1,1
# is the best. The stride should never be more than the kernel_size dimensions.
# numK1 = the number of kernels in this convolution layer
#******************************************************************************
#***************************** Instruction ************************************
# If you change the kernel size or the maxpool size you have to make sure that 
# they don't go past the dimensions of the actuall matrix. Look at explanation 
# above ^^^^^ 
epochs = 30
numK1 = 64
model.add(Conv2D(numK1, kernel_size=2, strides=(1, 1),
                 activation='relu',
                 input_shape=input_shape,
                 data_format="channels_last"))
#******************************************************************************
#***************** This makes the pooling layer********************************
#pool_size: chooses the size of the pooling filter. 2,2 is the smallest, whil 
#anything larger just filter the data even more. 
#strides: Should always be equal to the pool_size. 
#******************************************************************************
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#******************************************************************************
#***************** This makes the second convolution layer ********************
# We don't need this other convolution layer unless we intend to make the 
# matrix dimensions bigger, Please look at explanation above regarding 
# adding convolution layer. For each one of these layers you are making the 
# Matrix smaller.... So you will have to worry about dimensionality issues. 
#******************************************************************************
# numK2 = 64
# model.add(Conv2D(numK2, kernel_size=5, activation='relu'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
#******************************************************************************
#This command will flatten the model so that it is prepared for the fully
#connected layer. 
#******************************************************************************
model.add(Flatten())

#******************************************************************************
#*********************** This trains the fully connected layer ****************
# fNodes: is the number of nodes in the fully connected layer 
# *****************************************************************************
#***************** INSTRUCTIONS ***********************************************
# You can change the number of nodes in the fully connected layer. 
fNodes = 5000
model.add(Dense(fNodes, activation='sigmoid'))


#******************************************************************************
#*********************** Trains the output layer ******************************
model.add(Dense(num_classes, activation='softmax'))

#*****************************************************************************
#*****************************************************************************
#*****************************************************************************
#************************** Runs the Model ***********************************

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adam(),
              metrics=['accuracy'])


class AccuracyHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.acc = []

    def on_epoch_end(self, batch, logs={}):
        self.acc.append(logs.get('acc'))

history = AccuracyHistory()

model.fit(trainData, trainLabels,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(testData, testLabels),
          callbacks=[history])
score = model.evaluate(testData, testLabels, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
plt.plot(range(1, epochs+1), history.acc)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
# plt.show()
plt.savefig('plot_numK1_'+str(numK1)+'_epochs_'+str(epochs)+'.png')
# del plt